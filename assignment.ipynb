{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fcera10/Lab04/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Here import all crucial packages etc."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Ywu7bCi4kqU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# Code here"
      ],
      "metadata": {
        "id": "SHTkT10_kqU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments\n",
        ")\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from transformers import EvalPrediction, pipeline"
      ],
      "metadata": {
        "id": "10i0X8czkqU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils\n",
        "\n",
        "Helper functions that you will use"
      ],
      "metadata": {
        "collapsed": false,
        "id": "IanbLSmjkqU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "#Code here"
      ],
      "metadata": {
        "id": "0l6eOMqskqU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "TztmRfDPkqU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "# Fine-Tuning BERT Model to Fake News detection"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lQfnBpkrkqU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Train, Validation and Test data\n",
        "\n",
        "Import all datasets and load and preprocess train and validation\n",
        "\n",
        "Link to direcotry with data: https://github.com/ArkadiusDS/NLP-Labs/tree/master/data/CoAID/"
      ],
      "metadata": {
        "collapsed": false,
        "id": "n-vITRuWkqU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T20:13:41.486063Z",
          "start_time": "2025-05-14T20:13:41.483303Z"
        },
        "id": "jueS4Ro-kqU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T20:13:42.046761Z",
          "start_time": "2025-05-14T20:13:42.040214Z"
        },
        "id": "fxzRA12gkqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and tokenizer\n",
        "\n",
        "Firstly create two dicts id2label and label2id and then load model and tokenizer\n",
        "Then use well-known distilled version of BERT model for faster fine-tuning: 'distilbert/distilbert-base-uncased' or any other model you wish."
      ],
      "metadata": {
        "collapsed": false,
        "id": "N8EsDwHCkqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T20:13:45.278032Z",
          "start_time": "2025-05-14T20:13:45.273486Z"
        },
        "id": "zI1PEZQYkqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize datasets and prepare it for fine-tuning\n",
        "\n",
        "You may use DisinformationDataset class for data preparation."
      ],
      "metadata": {
        "collapsed": false,
        "id": "whiddemzkqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T20:13:47.959638Z",
          "start_time": "2025-05-14T20:13:47.955082Z"
        },
        "id": "4GLUlMewkqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune BERT model on at least 3 sets of hyperparameters\n",
        "\n",
        "Check F1 score, precision and recall for each fine-tuned model and at the end choose set of hyperparameters that gives you best results. For each set of hyperparameters write down the final metrics. You need to acheive at least below result on validation dataset:\n",
        "\n",
        "\"f1\": 0.91,\n",
        "\"recall\": 0.91,\n",
        "\"precision\": 0.91\n",
        "\n",
        "Remember you need to achieve these minimum results on VALIDATION dataset and the best model on validation dataset will have to be used for predictions on test dataset.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fNkGfmvckqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T20:13:50.601803Z",
          "start_time": "2025-05-14T20:13:50.598773Z"
        },
        "id": "lqYve2i7kqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final prediction on test dataset\n",
        "\n",
        "Take best model and hyperparameters on validation and predict on test dataset. Compute evaluation metrics f1, precision and recall."
      ],
      "metadata": {
        "collapsed": false,
        "id": "QrKLQ-EykqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T19:44:16.981717Z",
          "start_time": "2025-05-14T19:44:16.918294Z"
        },
        "id": "aPSiPRe8kqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final file with results and description"
      ],
      "metadata": {
        "collapsed": false,
        "id": "KCpihP8QkqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "import json"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-04T15:21:11.331626Z",
          "start_time": "2025-05-04T15:21:11.312816Z"
        },
        "id": "JyyfFl2CkqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All keys in your dictionary have to be the same as below. The only changes you should do in terms of keys is changing names of hyperparameters, e.g. instead of key \"name_of_hyperparameter_0\" if you used learning rate then write \"learning_rate\". Other important information in the dictionary below and comments. Each value says what is expected.\n",
        "\n",
        "Example dictionary provided under the template."
      ],
      "metadata": {
        "collapsed": false,
        "id": "XuVwdSYtkqU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Template for your structured resulting file"
      ],
      "metadata": {
        "collapsed": false,
        "id": "EEqedKdUkqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "data = {\n",
        "    # Everything in experiment_0 is related to experiment on validation dataset, so metrics are computed on validation dataset etc.\n",
        "    \"experiment_0\": {\n",
        "        \"model\": \"model name\",\n",
        "        \"hyperparameters\": {\n",
        "            \"name_of_hyperparameter_0\": \"value in str or float - You need to play with at least two different hyperparameters so at least name_of_hyperparameter_0 and name_of_hyperparameter_1\",\n",
        "            \"name_of_hyperparameter_1\": \"value in str or float\"\n",
        "        },\n",
        "        \"f1_score\": \"value in float\",\n",
        "        \"precision\": \"value in float\",\n",
        "        \"recall\": \"value in float\",\n",
        "        \"description\": \"Unique description one of the approach - it has to be different for each experiment.\"\n",
        "    },\n",
        "    # Everything in experiment_1 is related to experiment on validation dataset, so metrics are computed on validation dataset etc.\n",
        "    \"experiment_1\": {\n",
        "        \"model\": \"model name\",\n",
        "        \"hyperparameters\": {\n",
        "            \"name_of_hyperparameter_0\": \"value in str or float\",\n",
        "            \"name_of_hyperparameter_1\": \"value in str or float\"\n",
        "        },\n",
        "        \"f1_score\": \"value in float\",\n",
        "        \"precision\": \"value in float\",\n",
        "        \"recall\": \"value in float\",\n",
        "        \"description\": \"Unique description two of the approach - it has to be different for each experiment.\"\n",
        "    },\n",
        "    # Everything in experiment_2 is related to experiment on validation dataset, so metrics are computed on validation dataset etc.\n",
        "    \"experiment_2\": {\n",
        "        \"model\": \"model name\",\n",
        "        \"hyperparameters\": {\n",
        "            \"name_of_hyperparameter_0\": \"value in str or float\",\n",
        "            \"name_of_hyperparameter_1\": \"value in str or float\"\n",
        "        },\n",
        "        \"f1_score\": \"value in float\",\n",
        "        \"precision\": \"value in float\",\n",
        "        \"recall\": \"value in float\",\n",
        "        \"description\": \"Unique description three of the approach - it has to be different for each experiment.\"\n",
        "    },\n",
        "    # Everything in final_prediction is related to prediction on test dataset, so metrics are computed on test dataset etc.\n",
        "    \"final_prediction\": {\n",
        "        \"model\": \"google-bert/bert-base-uncased\",\n",
        "        \"experiment_chosen\": \"experiment_0 or experiment_1 or experiment_2\",\n",
        "        \"hyperparameters\": {\n",
        "            \"name_of_hyperparameter_0\": \"value in str or float\",\n",
        "            \"name_of_hyperparameter_1\": \"value in str or float\"\n",
        "        },\n",
        "        \"f1_score\": \"value in float\",\n",
        "        \"precision\": \"value in float\",\n",
        "        \"recall\": \"value in float\",\n",
        "        \"description\": \"Unique description four of the final results and prediction - it has to be different and here you will describe results on test dataset.\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T13:15:27.971126Z",
          "start_time": "2025-05-14T13:15:27.959036Z"
        },
        "id": "_QepKIF8kqU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "with open(\"experiments_name_surname_student_id.json\", \"w\") as f:\n",
        "    json.dump(data, f, indent=4)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T13:15:36.578291Z",
          "start_time": "2025-05-14T13:15:36.564453Z"
        },
        "id": "6Lidmk2-kqU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example final file"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9hEchgw9kqU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"experiment_0\": {\n",
        "        \"model\": \"google-bert/bert-base-uncased\",\n",
        "        \"hyperparameters\": {\n",
        "            \"learning_rate\": \"float\",\n",
        "            \"warmap_ratio\": \"float\",\n",
        "            \"weight_decay\": \"float\"\n",
        "        },\n",
        "        \"f1_score\": \"float\",\n",
        "        \"precision\": \"float\",\n",
        "        \"recall\": \"float\",\n",
        "        \"description\": \"This experiment fine-tuned the google-bert/bert-base-uncased model for binary classification using a learning rate of 1e-5 and a warmup ratio of 0.06. The model achieved an F1-score of 0.76, with a strong recall of 0.85, indicating high sensitivity to positive cases. Precision was moderate at 0.65, suggesting some trade-off in false positives. The setup demonstrates effective recall-oriented performance in identifying relevant instances.\"\n",
        "    },\n",
        "    \"experiment_1\": {\n",
        "        \"model\": \"google-bert/bert-base-uncased\",\n",
        "        \"hyperparameters\": {\n",
        "            \"learning_rate\": \"float\",\n",
        "            \"weight_decay\": \"float\"\n",
        "        },\n",
        "        \"f1_score\": \"float\",\n",
        "        \"precision\": \"float\",\n",
        "        \"recall\": \"float\",\n",
        "        \"description\": \"Unique description two of the approach - it has to be different for each experiment. Everything in experiment_1 is related to experiment on validation dataset, so metrics are computed on validation dataset etc.\"\n",
        "    },\n",
        "    \"experiment_2\": {\n",
        "        \"model\": \"google-bert/bert-base-uncased\",\n",
        "        \"hyperparameters\": {\n",
        "            \"learning_rate\": \"float\",\n",
        "            \"num_train_epochs\": \"int\",\n",
        "            \"weight_decay\": \"float\"\n",
        "        },\n",
        "        \"f1_score\": \"float\",\n",
        "        \"precision\": \"float\",\n",
        "        \"recall\": \"float\",\n",
        "        \"description\": \"Unique description three of the approach - it has to be different for each experiment. Everything in experiment_2 is related to experiment on validation dataset, so metrics are computed on validation dataset etc.\"\n",
        "    },\n",
        "    \"final_prediction\": {\n",
        "        \"model\": \"google-bert/bert-base-uncased\",\n",
        "        \"experiment_chosen\": \"experiment_0\",\n",
        "        \"hyperparameters\": {\n",
        "            \"learning_rate\": \"float\",\n",
        "            \"warmap_ratio\": \"float\"\n",
        "        },\n",
        "        \"f1_score\": \"float\",\n",
        "        \"precision\": \"float\",\n",
        "        \"recall\": \"float\",\n",
        "        \"description\": \"Unique description four of the final results and prediction - it has to be different and here you will describe results on test dataset. Everything in final_prediction is related to prediction on test dataset, so metrics are computed on test dataset etc.\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T13:16:07.131068Z",
          "start_time": "2025-05-14T13:16:07.123378Z"
        },
        "id": "lAg2J8fekqU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "with open(\"experiments_Arkadiusz_Modzelewski_29580.json\", \"w\") as f:\n",
        "    json.dump(data, f, indent=4)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-14T13:16:08.560046Z",
          "start_time": "2025-05-14T13:16:08.553870Z"
        },
        "id": "OP17hybBkqU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "3lCRGoNmkqU4"
      }
    }
  ]
}